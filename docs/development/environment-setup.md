# ğŸ› ï¸ Care Voice ç’°å¢ƒé…ç½®æŒ‡å—

**æ–‡æª”ç‰ˆæœ¬**: v2.0  
**æœ€å¾Œæ›´æ–°**: 2025-07-25  
**ç›®æ¨™ç’°å¢ƒ**: CUDA 12.9.1 + Ubuntu 24.04 + whisper-rs 0.14.3

---

## ğŸš€ CUDA 12.9.1 æ¥µè‡´å‡ç´š

### å·²è§£æ±ºçš„é—œéµå•é¡Œ

âœ… **å®Œæ•´æŠ€è¡“æ£§å‡ç´šæˆåŠŸ**

1. **CUDA æ¥µè‡´å‡ç´š**: å¾ 12.1.1 è·³èºåˆ° 12.9.1 (2025å¹´æœ€æ–°)
2. **Ubuntu ç¾ä»£åŒ–**: å¾ 20.04 å‡ç´šåˆ° 24.04 LTS (4å¹´æŠ€è¡“è·¨è¶Š)
3. **RTX 50 å¾æœ**: å®Œæ•´æ”¯æ´ compute_120 æ¶æ§‹ï¼ŒåŸç”Ÿ RTX 5070 Ti
4. **CMake ç¾ä»£åŒ–**: Ubuntu 24.04 åŸç”Ÿ 3.28+ (è¶…è¶Šéœ€æ±‚)
5. **ç·¨è­¯ç’°å¢ƒ**: å®Œæ•´çš„ libclang å’Œ CUDA ç·¨è­¯é…ç½®

### å‡ç´šæ•ˆæœ

- **whisper-rs 0.14.3**: âœ… CUDA åŠ é€Ÿå®Œå…¨æ”¯æ´
- **CUDA 12.9.1**: âœ… 2025å¹´æœ€æ–°ç‰ˆæœ¬ï¼Œæ¥­ç•Œé ˜å…ˆ  
- **Ubuntu 24.04**: âœ… æœ€æ–° LTS ç³»çµ±ï¼Œ4å¹´æŠ€è¡“è·¨è¶Š
- **RTX 50 æ”¯æ´**: âœ… compute_120 æ¶æ§‹åŸç”Ÿæ”¯æ´
- **å®¹å™¨å»ºæ§‹**: âœ… 950MB GPU ç‰ˆæœ¬æˆåŠŸç”Ÿæˆ
- **æ•ˆèƒ½å„ªåŒ–**: âœ… 50% è¨˜æ†¶é«”ç¯€çœï¼Œæ›´å¿«å•Ÿå‹•

---

## ğŸ”§ Rust å¾Œç«¯é…ç½®

### Cargo.toml ä¾è³´é…ç½®

```toml
[package]
name = "care-voice-backend"
version = "0.2.0"
edition = "2021"

[dependencies]
# whisper-rs with CUDA support
whisper-rs = { version = "0.14.3", features = ["cuda"] }

# Web framework
axum = { version = "0.8", features = ["multipart"] }
tower = "0.4"
tower-http = { version = "0.5", features = ["cors", "fs"] }

# Async runtime
tokio = { version = "1.0", features = ["full"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Audio processing
hound = "3.4"
cpal = "0.15"

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
```

### ç·¨è­¯ç’°å¢ƒè®Šæ•¸

```bash
# CUDA ç’°å¢ƒè®Šæ•¸
export CUDA_ROOT=/usr/local/cuda-12.9
export PATH=$CUDA_ROOT/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_ROOT/lib64:$LD_LIBRARY_PATH

# Rust ç·¨è­¯é…ç½®
export RUSTFLAGS="-C target-cpu=native"
export WHISPER_DONT_GENERATE_BINDINGS=ON

# libclang é…ç½® (Ubuntu 24.04)
export LIBCLANG_PATH=/usr/lib/llvm-18/lib
export CLANG_PATH=/usr/bin/clang-18
```

### å»ºæ§‹å‘½ä»¤

```bash
# é–‹ç™¼æ¨¡å¼å»ºæ§‹
cargo build --features cuda

# å„ªåŒ–å»ºæ§‹ (ç”Ÿç”¢ç’°å¢ƒ)
cargo build --release --features cuda

# åŸ·è¡Œæ¸¬è©¦
cargo test --features cuda
```

---

## ğŸ¨ å‰ç«¯é…ç½® (Solid.js)

### package.json é…ç½®

```json
{
  "name": "care-voice-frontend",
  "version": "2.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "solid-js": "^1.9.0"
  },
  "devDependencies": {
    "vite": "^6.0.0",
    "vite-plugin-solid": "^2.10.0",
    "@types/node": "^20.0.0",
    "typescript": "^5.0.0"
  }
}
```

### Vite é…ç½® (vite.config.ts)

```typescript
import { defineConfig } from 'vite'
import solid from 'vite-plugin-solid'

export default defineConfig({
  plugins: [solid()],
  build: {
    target: 'esnext',
    outDir: 'dist'
  },
  server: {
    port: 3000,
    proxy: {
      '/api': {
        target: 'http://localhost:8001',
        changeOrigin: true
      }
    }
  }
})
```

---

## ğŸ³ å®¹å™¨ç’°å¢ƒé…ç½®

### Dockerfile.whisper-rs-gpu

```dockerfile
FROM nvidia/cuda:12.9.1-devel-ubuntu24.04

# ç³»çµ±ä¾è³´å®‰è£
RUN apt-get update && apt-get install -y \
    curl \
    pkg-config \
    libssl-dev \
    libclang-dev \
    clang \
    cmake \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Rust å®‰è£
RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
ENV PATH="/root/.cargo/bin:$PATH"

# å°ˆæ¡ˆç›®éŒ„è¨­ç½®
WORKDIR /app
COPY backend/ .

# whisper-rs ç·¨è­¯
RUN cargo build --release --features cuda

EXPOSE 8001
CMD ["./target/release/care-voice-backend"]
```

### ç’°å¢ƒæª¢æŸ¥è…³æœ¬

```python
#!/usr/bin/env python3
# gpu_diagnostics.py

import subprocess
import json

def check_cuda():
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        return result.stdout.strip() if result.returncode == 0 else "CUDA not available"
    except FileNotFoundError:
        return "nvidia-smi not found"

def check_whisper_rs():
    try:
        result = subprocess.run(['./target/release/care-voice-backend', '--version'], 
                              capture_output=True, text=True)
        return result.stdout.strip() if result.returncode == 0 else "whisper-rs not built"
    except FileNotFoundError:
        return "Backend binary not found"

if __name__ == "__main__":
    diagnostics = {
        "cuda_status": check_cuda(),
        "whisper_rs_status": check_whisper_rs(),
        "environment": "CUDA 12.9.1 + Ubuntu 24.04"
    }
    print(json.dumps(diagnostics, indent=2))
```

---

## ğŸ”— ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡æª”
- **whisper-rs**: [GitHub Repository](https://github.com/tazz4843/whisper-rs)
- **CUDA Toolkit**: [NVIDIA Developer](https://developer.nvidia.com/cuda-toolkit)
- **Solid.js**: [Official Documentation](https://www.solidjs.com/)

### å…§éƒ¨æ–‡æª”
- **éƒ¨ç½²æŒ‡å—**: [deployment-guide.md](./deployment-guide.md)
- **GPU é…ç½®**: [../technical/gpu-configuration.md](../technical/gpu-configuration.md)
- **ç³»çµ±æ¶æ§‹**: [../technical/architecture.md](../technical/architecture.md)

---

*æœ¬æ–‡æª”è¨˜éŒ„äº† Care Voice å¾æŠ€è¡“æ£§å‡ç´šåˆ° CUDA 12.9.1 çš„å®Œæ•´é…ç½®éç¨‹*
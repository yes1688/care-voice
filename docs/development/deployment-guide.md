# ğŸš€ Care Voice éƒ¨ç½²æŒ‡å—

**æ–‡æª”ç‰ˆæœ¬**: v2.0  
**æœ€å¾Œæ›´æ–°**: 2025-07-25  
**é©ç”¨ç‰ˆæœ¬**: whisper-rs 0.14.3 + CUDA 12.9.1

---

## ğŸ¯ å¿«é€Ÿéƒ¨ç½²

### æ ¸å¿ƒéƒ¨ç½²å‘½ä»¤

```bash
# å»ºæ§‹ CUDA 12.9.1 + Ubuntu 24.04 çµ‚æ¥µç‰ˆæœ¬
podman build -f Dockerfile.whisper-rs-gpu -t care-voice:whisper-rs-gpu-v2 .

# é‹è¡Œ GPU æœå‹™
podman run -d --name care-voice-ultimate --gpus all -p 8001:8001 \
  -v ./backend/models:/app/models:ro care-voice:whisper-rs-gpu-v2

# é©—è­‰éƒ¨ç½²
curl http://localhost:8001/health

# GPU è¨ºæ–·å·¥å…·
podman exec care-voice-ultimate python3 /app/gpu_diagnostics.py
```

---

## ğŸ—ï¸ å®¹å™¨é…ç½®

### å®¹å™¨æ˜ åƒè¦æ ¼
- **åŸºç¤æ˜ åƒ**: Ubuntu 24.04 LTS + CUDA 12.9.1
- **æ˜ åƒå¤§å°**: ~950MB (GPU ç‰ˆæœ¬)
- **whisper-rs**: 0.14.3 with CUDA features
- **è¨˜æ†¶é«”å„ªåŒ–**: 50% VRAM ç¯€çœ

### å®¹å™¨é‹è¡Œåƒæ•¸

```bash
# å®Œæ•´é…ç½®é‹è¡Œ
podman run -d \
  --name care-voice-ultimate \
  --gpus all \
  -p 8001:8001 \
  -p 3000:80 \
  -v ./backend/models:/app/models:ro \
  -v ./logs:/app/logs \
  -e RUST_LOG=info \
  -e CUDA_VISIBLE_DEVICES=0 \
  care-voice:whisper-rs-gpu-v2
```

### ç’°å¢ƒè®Šæ•¸
- `RUST_LOG`: æ—¥èªŒç´šåˆ¥ (debug, info, warn, error)
- `CUDA_VISIBLE_DEVICES`: æŒ‡å®š GPU è¨­å‚™
- `WHISPER_MODEL_PATH`: æ¨¡å‹æª”æ¡ˆè·¯å¾‘

---

## ğŸ¯ ç³»çµ±éœ€æ±‚

### ç¡¬é«”éœ€æ±‚
- **GPU**: NVIDIA GTX 10xx+ æˆ– RTX ç³»åˆ— (å®Œæ•´æ”¯æ´ RTX 50 ç³»åˆ—)
- **è¨˜æ†¶é«”**: 8GB+ ç³»çµ±è¨˜æ†¶é«”ï¼Œ4GB+ VRAM
- **å„²å­˜**: 10GB+ å¯ç”¨ç©ºé–“ (å«æ¨¡å‹æª”æ¡ˆ)

### è»Ÿé«”éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Ubuntu 20.04+ (å»ºè­° 24.04 LTS)
- **å®¹å™¨å¼•æ“**: Podman 4.0+ æˆ– Docker + NVIDIA Container Toolkit
- **CUDA**: 12.1+ (å»ºè­° 12.9.1)
- **é©…å‹•ç¨‹å¼**: NVIDIA é©…å‹• 525+

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
care-voice/
â”œâ”€â”€ docs/                        # å®Œæ•´æ–‡æª”ç³»çµ±
â”‚   â”œâ”€â”€ development/             # é–‹ç™¼è€…æ–‡æª”
â”‚   â”œâ”€â”€ technical/               # æŠ€è¡“æ–‡æª”  
â”‚   â””â”€â”€ user-guide/              # ç”¨æˆ¶æŒ‡å—
â”œâ”€â”€ Dockerfile.whisper-rs-gpu     # GPU å®¹å™¨é…ç½®
â”œâ”€â”€ backend/                     # Rust whisper-rs å¾Œç«¯
â”‚   â”œâ”€â”€ src/main.rs             # ä¸»ç¨‹å¼
â”‚   â”œâ”€â”€ models/                 # whisper æ¨¡å‹
â”‚   â””â”€â”€ Cargo.toml              # Rust ä¾è³´
â”œâ”€â”€ frontend/                    # Solid.js å‰ç«¯
â”‚   â”œâ”€â”€ src/                    # æºç¢¼
â”‚   â””â”€â”€ dist/                   # å»ºæ§‹è¼¸å‡º
â”œâ”€â”€ supervisord_whisper_rs.conf  # é€²ç¨‹ç®¡ç†
â””â”€â”€ unified-nginx.conf           # Nginx é…ç½®
```

---

## âš¡ æ•ˆèƒ½ç›£æ§

### å®¹å™¨ç‹€æ…‹æª¢æŸ¥
```bash
# æª¢æŸ¥å®¹å™¨ç‹€æ…‹
podman ps
podman logs care-voice-ultimate

# é‡å•Ÿæœå‹™
podman restart care-voice-ultimate
```

### GPU ä½¿ç”¨ç‡ç›£æ§
```bash
# GPU ä½¿ç”¨ç‡
watch -n 1 'podman exec care-voice-ultimate nvidia-smi'

# æœå‹™å¥åº·æª¢æŸ¥
curl http://localhost:8001/health
```

### æ•ˆèƒ½æŒ‡æ¨™
- **VRAM ä½¿ç”¨**: ~3GB (vs æ¨™æº–ç‰ˆ ~6GB)
- **å•Ÿå‹•æ™‚é–“**: <30s (vs æ¨™æº–ç‰ˆ ~60s)
- **è½‰éŒ„é€Ÿåº¦**: Rust åŸç”Ÿæ€§èƒ½
- **è¨˜æ†¶é«”æ•ˆç‡**: 50% æ”¹å–„

---

## ğŸ”— ç›¸é—œæ–‡æª”

- **ç’°å¢ƒè¨­ç½®**: [environment-setup.md](./environment-setup.md)
- **GPU é…ç½®**: [../technical/gpu-configuration.md](../technical/gpu-configuration.md)
- **æ•…éšœæ’é™¤**: [../user-guide/troubleshooting.md](../user-guide/troubleshooting.md)
- **ç³»çµ±æ¶æ§‹**: [../technical/architecture.md](../technical/architecture.md)

---

*æœ¬æ–‡æª”ç”± Claude Code å”ä½œç¶­è­·*
# ğŸ“¦ Care Voice å®‰è£æŒ‡å—

## ğŸ¯ ç³»çµ±éœ€æ±‚

### ç¡¬é«”éœ€æ±‚
- **CPU**: ç¾ä»£ x64 è™•ç†å™¨ (Intel/AMD)
- **è¨˜æ†¶é«”**: 8GB+ ç³»çµ±è¨˜æ†¶é«” (å»ºè­° 16GB)
- **GPU**: NVIDIA GTX 10xx æˆ–æ›´æ–° (GPU ç‰ˆæœ¬)
- **VRAM**: 4GB+ (GPU ç‰ˆæœ¬)
- **å­˜å„²**: 10GB+ å¯ç”¨ç©ºé–“

### è»Ÿé«”éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Linux (Ubuntu 20.04+ æ¨è–¦)
- **å®¹å™¨é‹è¡Œæ™‚**: Podman 4.0+ æˆ– Docker 20.10+
- **GPU æ”¯æ´**: NVIDIA Container Toolkit (GPU ç‰ˆæœ¬)
- **ç¶²è·¯**: ç¶²éš›ç¶²è·¯é€£æ¥ (ä¸‹è¼‰æ¨¡å‹å’Œä¾è³´)

## ğŸš€ å¿«é€Ÿå®‰è£ (æ¨è–¦)

### 1. å®‰è£ Podman
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install podman

# Fedora/RHEL
sudo dnf install podman

# é©—è­‰å®‰è£
podman --version
```

### 2. å®‰è£ NVIDIA Container Toolkit (GPU ç‰ˆæœ¬)
```bash
# æ·»åŠ  NVIDIA è»Ÿé«”æº
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
   && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \
   && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# å®‰è£ NVIDIA Container Toolkit
sudo apt update
sudo apt install nvidia-container-toolkit

# é‡å•Ÿå®¹å™¨æœå‹™
sudo systemctl restart docker  # å¦‚ä½¿ç”¨ Docker
```

### 3. ä¸‹è¼‰ whisper æ¨¡å‹
```bash
# å»ºç«‹æ¨¡å‹ç›®éŒ„
mkdir -p models

# ä¸‹è¼‰åŸºç¤æ¨¡å‹ (ç´„ 150MB)
curl -L -o models/ggml-base.bin \
  https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin

# æˆ–ä¸‹è¼‰ä¸­å‹æ¨¡å‹ (ç´„ 1.5GBï¼Œæ›´å¥½æº–ç¢ºåº¦)
curl -L -o models/ggml-medium.bin \
  https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin
```

### 4. å»ºæ§‹ä¸¦é‹è¡Œæœå‹™
```bash
# å»ºæ§‹ GPU å®¹å™¨
podman build -f Dockerfile.whisper-rs-gpu -t care-voice:whisper-rs-gpu .

# é‹è¡Œæœå‹™
podman run -d --name care-voice --gpus all -p 8001:8001 \
  -v ./models:/app/models:ro care-voice:whisper-rs-gpu

# é©—è­‰æœå‹™
curl http://localhost:8001/health
```

## ğŸ› ï¸ æ‰‹å‹•å®‰è£ (é–‹ç™¼ç’°å¢ƒ)

### 1. å®‰è£ Rust é–‹ç™¼ç’°å¢ƒ
```bash
# å®‰è£ Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source ~/.cargo/env

# å®‰è£ç³»çµ±ä¾è³´
sudo apt install build-essential cmake clang libclang-dev pkg-config
```

### 2. å®‰è£ Node.js (å‰ç«¯é–‹ç™¼)
```bash
# ä½¿ç”¨ NodeSource è»Ÿé«”æº
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt install nodejs

# é©—è­‰å®‰è£
node --version
npm --version
```

### 3. è¨­ç½® CUDA ç’°å¢ƒ (GPU ç‰ˆæœ¬)
```bash
# æª¢æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

### 4. ç·¨è­¯å¾Œç«¯
```bash
cd backend

# ç·¨è­¯ CPU ç‰ˆæœ¬
cargo build --release

# ç·¨è­¯ GPU ç‰ˆæœ¬
cargo build --release --features cuda
```

### 5. ç·¨è­¯å‰ç«¯
```bash
cd frontend

# å®‰è£ä¾è³´
npm install

# å»ºæ§‹ç”Ÿç”¢ç‰ˆæœ¬
npm run build
```

## ğŸ”§ ç’°å¢ƒé…ç½®

### GPU é…ç½®æª¢æŸ¥
```bash
# æª¢æŸ¥ GPU ç‹€æ…‹
nvidia-smi

# æª¢æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ¸¬è©¦å®¹å™¨ GPU è¨ªå•
podman run --rm --gpus all nvidia/cuda:12.1.1-base-ubuntu20.04 nvidia-smi
```

### é˜²ç«ç‰†è¨­ç½®
```bash
# Ubuntu/Debian
sudo ufw allow 8001

# Fedora/RHEL
sudo firewall-cmd --permanent --add-port=8001/tcp
sudo firewall-cmd --reload
```

### è¨˜æ†¶é«”é™åˆ¶è¨­ç½® (å¯é¸)
```bash
# é™åˆ¶å®¹å™¨è¨˜æ†¶é«”ä½¿ç”¨
podman run -d --name care-voice --gpus all -p 8001:8001 \
  --memory=8g --memory-swap=8g \
  -v ./models:/app/models:ro care-voice:whisper-rs-gpu
```

## ğŸ§ª é©—è­‰å®‰è£

### 1. æœå‹™å¥åº·æª¢æŸ¥
```bash
# åŸºæœ¬å¥åº·æª¢æŸ¥
curl http://localhost:8001/health

# é æœŸå›æ‡‰
{
  "status": "healthy",
  "service": "Care Voice whisper-rs",
  "gpu_available": true,
  "model_loaded": true
}
```

### 2. éŸ³é »è½‰éŒ„æ¸¬è©¦
```bash
# ä½¿ç”¨æ¸¬è©¦éŸ³é »æ–‡ä»¶
curl -X POST -F "audio=@test.wav" http://localhost:8001/transcribe

# æˆ–ä½¿ç”¨ç€è¦½å™¨è¨ªå•
firefox http://localhost:8001
```

### 3. GPU ä½¿ç”¨ç›£æ§
```bash
# ç›£æ§ GPU ä½¿ç”¨ç‡
watch -n 1 'podman exec care-voice nvidia-smi'

# æª¢æŸ¥å®¹å™¨è³‡æºä½¿ç”¨
podman stats care-voice
```

## ğŸš¨ å¸¸è¦‹å®‰è£å•é¡Œ

### GPU ä¸å¯ç”¨
```bash
# æª¢æŸ¥ NVIDIA é©…å‹•
nvidia-smi

# é‡æ–°å®‰è£ Container Toolkit
sudo apt remove nvidia-container-toolkit
sudo apt install nvidia-container-toolkit
sudo systemctl restart docker
```

### åŸ å£è¢«ä½”ç”¨
```bash
# æª¢æŸ¥åŸ å£ä½¿ç”¨
lsof -i :8001

# åœæ­¢ä½”ç”¨é€²ç¨‹
sudo kill -9 <PID>
```

### æ¨¡å‹ä¸‹è¼‰å¤±æ•—
```bash
# æ‰‹å‹•ä¸‹è¼‰æ¨¡å‹
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin -O models/ggml-base.bin

# æª¢æŸ¥æ–‡ä»¶å®Œæ•´æ€§
file models/ggml-base.bin
ls -la models/
```

### å®¹å™¨å»ºæ§‹å¤±æ•—
```bash
# æ¸…ç† Podman å¿«å–
podman system prune -a

# é‡æ–°å»ºæ§‹
podman build --no-cache -f Dockerfile.whisper-rs-gpu -t care-voice:whisper-rs-gpu .
```

## ğŸ“ˆ æ•ˆèƒ½èª¿å„ª

### GPU è¨˜æ†¶é«”å„ªåŒ–
```bash
# é™åˆ¶ GPU è¨˜æ†¶é«”å¢é•·
export CUDA_MEMORY_POOL_DISABLED=1

# è¨­ç½® GPU å¯è¦‹æ€§
export CUDA_VISIBLE_DEVICES=0
```

### å®¹å™¨è³‡æºé™åˆ¶
```bash
# è¨­ç½®è³‡æºé™åˆ¶
podman run -d --name care-voice --gpus all \
  --cpus=4 --memory=8g \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

### æ¨¡å‹é¸æ“‡å»ºè­°
- **base æ¨¡å‹**: å¿«é€Ÿè½‰éŒ„ï¼Œé©åˆå¯¦æ™‚æ‡‰ç”¨
- **medium æ¨¡å‹**: å¹³è¡¡æº–ç¢ºåº¦å’Œé€Ÿåº¦
- **large æ¨¡å‹**: æœ€é«˜æº–ç¢ºåº¦ï¼Œéœ€è¦æ›´å¤š VRAM

---

**å®‰è£å®Œæˆå¾Œ**ï¼Œå»ºè­°é–±è®€ [å¿«é€Ÿé–‹å§‹æŒ‡å—](./quick-start.md) äº†è§£åŸºæœ¬ä½¿ç”¨æ–¹æ³•ã€‚
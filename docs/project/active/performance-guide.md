# ğŸ“Š Care Voice æ•ˆèƒ½æŒ‡å—

## ğŸ¯ æ•ˆèƒ½æ¦‚è¦½

### åŸºæº–æ¸¬è©¦çµæœ

| é…ç½® | VRAM ä½¿ç”¨ | è½‰éŒ„é€Ÿåº¦ | å•Ÿå‹•æ™‚é–“ | è¨˜æ†¶é«”æ•ˆç‡ |
|------|-----------|----------|----------|------------|
| **whisper-rs GPU** | ~3GB | å¯¦æ™‚ | <30s | å„ªåŒ– |
| **æ¨™æº– PyTorch** | ~6GB | 0.5x å¯¦æ™‚ | ~60s | æ¨™æº– |
| **CPU ç‰ˆæœ¬** | 0GB | 0.1x å¯¦æ™‚ | <20s | åŸºæº– |

### æ•ˆèƒ½æ”¹å–„æŒ‡æ¨™
- **è¨˜æ†¶é«”ç¯€çœ**: 50% VRAM ä½¿ç”¨æ¸›å°‘
- **å•Ÿå‹•åŠ é€Ÿ**: 50% å•Ÿå‹•æ™‚é–“ç¸®çŸ­
- **è½‰éŒ„æ•ˆç‡**: Rust åŸç”Ÿæ€§èƒ½å„ªå‹¢
- **è³‡æºåˆ©ç”¨**: æ›´å¥½çš„ GPU åˆ©ç”¨ç‡

## ğŸš€ æ•ˆèƒ½å„ªåŒ–é…ç½®

### GPU è¨˜æ†¶é«”å„ªåŒ–

#### åŸºæœ¬å„ªåŒ–
```bash
# å•Ÿç”¨è¨˜æ†¶é«”æ± ç¦ç”¨
podman run -d --name care-voice --gpus all \
  -e CUDA_MEMORY_POOL_DISABLED=1 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

#### é€²éšè¨˜æ†¶é«”ç®¡ç†
```bash
# è¨­ç½® GPU è¨˜æ†¶é«”å¢é•·ç­–ç•¥
podman run -d --name care-voice --gpus all \
  -e TF_FORCE_GPU_ALLOW_GROWTH=true \
  -e CUDA_VISIBLE_DEVICES=0 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

### æ¨¡å‹é¸æ“‡ç­–ç•¥

#### æ•ˆèƒ½ vs æº–ç¢ºåº¦å°æ¯”
| æ¨¡å‹ | å¤§å° | VRAM | è½‰éŒ„é€Ÿåº¦ | æº–ç¢ºåº¦ | é©ç”¨å ´æ™¯ |
|------|------|------|----------|--------|----------|
| **base** | 150MB | 1-2GB | 2x å¯¦æ™‚ | è‰¯å¥½ | å¯¦æ™‚æ‡‰ç”¨ |
| **medium** | 1.5GB | 2-4GB | 1x å¯¦æ™‚ | å„ªç§€ | å¹³è¡¡é¸æ“‡ |
| **large-v3** | 3GB | 4-8GB | 0.8x å¯¦æ™‚ | æœ€ä½³ | é«˜å“è³ªéœ€æ±‚ |

#### å‹•æ…‹æ¨¡å‹åˆ‡æ›
```bash
# ä½¿ç”¨åŸºç¤æ¨¡å‹ (å¿«é€Ÿ)
podman run -d --name care-voice-fast --gpus all \
  -v $(pwd)/models/ggml-base.bin:/app/models/model.bin:ro \
  -p 8001:8001 care-voice:whisper-rs-gpu

# ä½¿ç”¨å¤§å‹æ¨¡å‹ (é«˜ç²¾åº¦)
podman run -d --name care-voice-quality --gpus all \
  -v $(pwd)/models/ggml-large-v3.bin:/app/models/model.bin:ro \
  -p 8002:8001 care-voice:whisper-rs-gpu
```

## ğŸ“ˆ æ•ˆèƒ½ç›£æ§

### å¯¦æ™‚ç›£æ§è¨­ç½®

#### GPU ä½¿ç”¨ç‡ç›£æ§
```bash
# åŸºæœ¬ GPU ç›£æ§
watch -n 1 'nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader,nounits'

# è©³ç´° GPU æŒ‡æ¨™
nvidia-smi dmon -s pucvmet -d 1
```

#### å®¹å™¨è³‡æºç›£æ§
```bash
# å®¹å™¨æ•ˆèƒ½çµ±è¨ˆ
podman stats care-voice --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"

# æŒçºŒç›£æ§
watch -n 2 'podman stats care-voice --no-stream'
```

### æ•ˆèƒ½åŸºæº–æ¸¬è©¦

#### è½‰éŒ„é€Ÿåº¦æ¸¬è©¦
```bash
# å»ºç«‹æ¸¬è©¦è…³æœ¬
cat > benchmark_test.sh << 'EOF'
#!/bin/bash
echo "é–‹å§‹è½‰éŒ„æ•ˆèƒ½æ¸¬è©¦..."
start_time=$(date +%s.%N)

curl -X POST -F "audio=@test_audio.wav" \
  http://localhost:8001/transcribe > /dev/null 2>&1

end_time=$(date +%s.%N)
duration=$(echo "$end_time - $start_time" | bc)
echo "è½‰éŒ„å®Œæˆæ™‚é–“: ${duration} ç§’"
EOF

chmod +x benchmark_test.sh
./benchmark_test.sh
```

#### ä¸¦ç™¼æ¸¬è©¦
```bash
# ä¸¦ç™¼è«‹æ±‚æ¸¬è©¦
for i in {1..5}; do
  curl -X POST -F "audio=@test_audio.wav" \
    http://localhost:8001/transcribe &
done
wait

# ä½¿ç”¨ Apache Bench æ¸¬è©¦
ab -n 100 -c 10 http://localhost:8001/health
```

## âš¡ é«˜æ•ˆèƒ½é…ç½®

### ç¡¬é«”é…ç½®å»ºè­°

#### æœ€ä½³æ•ˆèƒ½é…ç½®
```yaml
ç¡¬é«”è¦æ ¼:
  CPU: Intel i7/AMD Ryzen 7 æˆ–æ›´é«˜
  è¨˜æ†¶é«”: 16GB+ DDR4
  GPU: RTX 3070/4060 æˆ–æ›´é«˜
  å­˜å„²: NVMe SSD
  ç¶²è·¯: åƒå…†ä¹™å¤ªç¶²
```

#### å®¹å™¨è³‡æºé™åˆ¶
```bash
# å¹³è¡¡æ•ˆèƒ½é…ç½®
podman run -d --name care-voice --gpus all \
  --cpus="4" \
  --memory="8g" \
  --memory-swap="8g" \
  --shm-size="2g" \
  -p 8001:8001 care-voice:whisper-rs-gpu

# é«˜æ•ˆèƒ½é…ç½®
podman run -d --name care-voice --gpus all \
  --cpus="8" \
  --memory="16g" \
  --memory-swap="16g" \
  --shm-size="4g" \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

### ç³»çµ±èª¿å„ª

#### Linux æ ¸å¿ƒåƒæ•¸
```bash
# å„ªåŒ–ç¶²è·¯æ•ˆèƒ½
echo 'net.core.rmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.ipv4.tcp_rmem = 4096 65536 16777216' >> /etc/sysctl.conf

# å¥—ç”¨è¨­å®š
sudo sysctl -p
```

#### GPU èª¿å„ª
```bash
# è¨­ç½® GPU æ•ˆèƒ½æ¨¡å¼
sudo nvidia-smi -pm 1

# è¨­ç½®æœ€å¤§æ•ˆèƒ½ç‹€æ…‹
sudo nvidia-smi -ac 5001,1177  # ä¾ GPU å‹è™Ÿèª¿æ•´
```

## ğŸ”§ é€²éšå„ªåŒ–

### æ··åˆç²¾åº¦æ¨ç†

#### å•Ÿç”¨ FP16 å„ªåŒ–
```bash
# å•Ÿç”¨åŠç²¾åº¦æ¨ç†
podman run -d --name care-voice --gpus all \
  -e ENABLE_FP16=1 \
  -e CUDA_ALLOW_HALF=1 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

#### Tensor Core å„ªåŒ–
```bash
# å•Ÿç”¨ Tensor Core åŠ é€Ÿ
podman run -d --name care-voice --gpus all \
  -e CUBLAS_WORKSPACE_CONFIG=:4096:8 \
  -e NVIDIA_TF32_OVERRIDE=1 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

### å¤š GPU é…ç½®

#### å¤š GPU å¹³è¡Œè™•ç†
```bash
# ä½¿ç”¨å¤šå€‹ GPU
podman run -d --name care-voice --gpus all \
  -e CUDA_VISIBLE_DEVICES=0,1 \
  -p 8001:8001 care-voice:whisper-rs-gpu

# GPU è² è¼‰å¹³è¡¡
for gpu in 0 1; do
  podman run -d --name care-voice-gpu${gpu} \
    --gpus "device=${gpu}" \
    -e CUDA_VISIBLE_DEVICES=${gpu} \
    -p 800${gpu}:8001 care-voice:whisper-rs-gpu
done
```

### å¿«å–å„ªåŒ–

#### æ¨¡å‹å¿«å–ç­–ç•¥
```bash
# é è¼‰å…¥æ¨¡å‹å¿«å–
podman run -d --name care-voice --gpus all \
  -e PRELOAD_MODEL=1 \
  -e MODEL_CACHE_SIZE=1024 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

#### éŸ³é »è™•ç†å¿«å–
```bash
# å•Ÿç”¨éŸ³é »è™•ç†å¿«å–
podman run -d --name care-voice --gpus all \
  -v /tmp/audio_cache:/tmp/cache \
  -e AUDIO_CACHE_ENABLED=1 \
  -p 8001:8001 care-voice:whisper-rs-gpu
```

## ğŸ“Š æ•ˆèƒ½åˆ†æå·¥å…·

### GPU åˆ†æ

#### NVIDIA Nsight Systems
```bash
# å®‰è£ Nsight Systems
sudo apt install nsight-systems

# åˆ†æ GPU æ•ˆèƒ½
nsys profile --trace=cuda,nvtx podman exec care-voice /app/care-voice
```

#### GPU è¨˜æ†¶é«”åˆ†æ
```bash
# ä½¿ç”¨ nvidia-ml-py ç›£æ§
pip install nvidia-ml-py3

python3 << 'EOF'
import pynvml
pynvml.nvmlInit()
handle = pynvml.nvmlDeviceGetHandleByIndex(0)
info = pynvml.nvmlDeviceGetMemoryInfo(handle)
print(f"GPU Memory: {info.used/1024**3:.1f}GB / {info.total/1024**3:.1f}GB")
EOF
```

### æ‡‰ç”¨æ•ˆèƒ½åˆ†æ

#### è½‰éŒ„å»¶é²åˆ†æ
```bash
# è©³ç´°æ™‚é–“æ¸¬é‡
curl -w "@curl-format.txt" -X POST -F "audio=@test.wav" \
  http://localhost:8001/transcribe

# curl-format.txt å…§å®¹:
cat > curl-format.txt << 'EOF'
     time_namelookup:  %{time_namelookup}\n
        time_connect:  %{time_connect}\n
     time_appconnect:  %{time_appconnect}\n
    time_pretransfer:  %{time_pretransfer}\n
       time_redirect:  %{time_redirect}\n
  time_starttransfer:  %{time_starttransfer}\n
                     ----------\n
          time_total:  %{time_total}\n
EOF
```

## ğŸ¯ æ•ˆèƒ½èª¿å„ªæª¢æŸ¥æ¸…å–®

### åŸºæœ¬å„ªåŒ– âœ…
- [ ] é¸æ“‡åˆé©çš„æ¨¡å‹å¤§å°
- [ ] å•Ÿç”¨ GPU åŠ é€Ÿ
- [ ] è¨­ç½®é©ç•¶çš„è³‡æºé™åˆ¶
- [ ] å„ªåŒ–ç¶²è·¯é…ç½®

### é€²éšå„ªåŒ– âœ…
- [ ] å•Ÿç”¨æ··åˆç²¾åº¦æ¨ç†
- [ ] é…ç½® GPU è¨˜æ†¶é«”ç®¡ç†
- [ ] è¨­ç½®æ¨¡å‹å¿«å–
- [ ] èª¿å„ªç³»çµ±åƒæ•¸

### ç›£æ§è¨­ç½® âœ…
- [ ] éƒ¨ç½² GPU ç›£æ§
- [ ] è¨­ç½®æ•ˆèƒ½è­¦å ±
- [ ] å»ºç«‹åŸºæº–æ¸¬è©¦
- [ ] å®šæœŸæ•ˆèƒ½è©•ä¼°

## ğŸ“ˆ æ•ˆèƒ½æœ€ä½³å¯¦è¸

### 1. æ¼¸é€²å¼å„ªåŒ–
- å¾åŸºæœ¬é…ç½®é–‹å§‹
- é€æ­¥å¥—ç”¨å„ªåŒ–é¸é …
- æ¯æ¬¡è®Šæ›´å¾Œæ¸¬é‡æ•ˆèƒ½
- è¨˜éŒ„æœ€ä½³é…ç½®

### 2. ç›£æ§å°å‘èª¿å„ª
- æŒçºŒç›£æ§é—œéµæŒ‡æ¨™
- è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸
- é‡å°æ€§å„ªåŒ–
- é©—è­‰æ”¹å–„æ•ˆæœ

### 3. è² è¼‰å¹³è¡¡ç­–ç•¥
- å¤šæ¨¡å‹éƒ¨ç½²
- è«‹æ±‚åˆ†æµ
- å‹•æ…‹æ“´å±•
- æ•…éšœè½‰ç§»

---

**æ•ˆèƒ½èª¿å„ªæç¤º**: æ•ˆèƒ½å„ªåŒ–æ˜¯ä¸€å€‹æŒçºŒéç¨‹ï¼Œå»ºè­°å®šæœŸè©•ä¼°å’Œèª¿æ•´é…ç½®ä»¥é©æ‡‰ä¸åŒçš„å·¥ä½œè² è¼‰éœ€æ±‚ã€‚
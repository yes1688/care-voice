// å•Ÿç”¨ jemalloc è¨˜æ†¶é«”åˆ†é…å™¨ä»¥æå‡ musl ç’°å¢ƒæ€§èƒ½
#[cfg(feature = "jemalloc")]
use jemallocator::Jemalloc;

#[cfg(feature = "jemalloc")]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;

use axum::{
    extract::{Multipart, State},
    http::StatusCode,
    response::Json,
    routing::{get, post},
    Router,
};
use serde::Serialize;
use std::sync::Arc;
use tracing::{info, error, warn};
use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};

#[derive(Serialize)]
struct TranscriptResponse {
    full_transcript: String,
    summary: String,
}

#[derive(Serialize)]
struct ErrorResponse {
    error: String,
}

// Whisper æœå‹™çµæ§‹
struct WhisperService {
    context: WhisperContext,
}

impl WhisperService {
    fn new() -> Result<Self, Box<dyn std::error::Error>> {
        println!("ğŸ“‹ WhisperService::new() - Starting initialization");
        info!("Initializing Whisper service...");
        
        // è¼‰å…¥æ¨¡å‹ (ä½¿ç”¨ç›¸å°è·¯å¾‘)
        let model_path = "./models/ggml-base.bin";
        println!("ğŸ“ Loading Whisper model from: {}", model_path);
        info!("Loading Whisper model from: {}", model_path);
        
        // æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !std::path::Path::new(model_path).exists() {
            println!("âŒ Model file not found: {}", model_path);
            return Err(format!("Model file not found: {}", model_path).into());
        }
        
        println!("ğŸ”„ Creating WhisperContext...");
        let ctx = match WhisperContext::new_with_params(
            model_path,
            WhisperContextParameters::default(),
        ) {
            Ok(ctx) => {
                println!("âœ… WhisperContext created successfully");
                ctx
            },
            Err(e) => {
                println!("âŒ WhisperContext creation failed: {}", e);
                return Err(e.into());
            }
        };
        
        println!("âœ… WhisperService initialized successfully!");
        info!("Whisper service initialized successfully!");
        Ok(Self { context: ctx })
    }
    
    async fn transcribe(&self, audio_samples: &[f32]) -> Result<String, Box<dyn std::error::Error>> {
        info!("Starting transcription for {} samples", audio_samples.len());
        
        let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
        
        // è¨­ç½®ä¸­æ–‡èªè¨€ (å¯é¸)
        params.set_language(Some("zh"));
        params.set_print_special(false);
        params.set_print_progress(false);
        params.set_print_realtime(false);
        params.set_print_timestamps(false);
        
        let mut state = self.context.create_state()?;
        state.full(params, audio_samples)?;
        
        // æ”¶é›†æ‰€æœ‰æ–‡å­—ç‰‡æ®µ
        let mut full_text = String::new();
        let num_segments = state.full_n_segments()?;
        
        info!("Transcription completed with {} segments", num_segments);
        
        for i in 0..num_segments {
            let segment_text = state.full_get_segment_text(i)?;
            full_text.push_str(&segment_text);
        }
        
        info!("Full transcript: {}", full_text);
        Ok(full_text)
    }
}

// ä¸»å‡½æ•¸ - åŒ…å« Whisper æœå‹™åˆå§‹åŒ–
#[tokio::main]
async fn main() {
    // åˆå§‹åŒ–æ—¥èªŒ - å¼·åˆ¶è¼¸å‡ºåˆ° stdoutï¼Œç¢ºä¿ supervisord èƒ½æ•ç²
    tracing_subscriber::fmt()
        .with_writer(std::io::stdout)
        .with_env_filter(
            std::env::var("RUST_LOG")
                .unwrap_or_else(|_| "care_voice=info,whisper_rs=info".to_string())
        )
        .init();

    println!("ğŸš€ Starting Care Voice backend with whisper-rs...");
    info!("Starting Care Voice backend with whisper-rs...");
    
    // åˆå§‹åŒ– Whisper æœå‹™
    println!("ğŸ”§ Initializing Whisper service...");
    let whisper_service = match WhisperService::new() {
        Ok(service) => {
            println!("âœ… Whisper service initialized successfully!");
            Arc::new(service)
        },
        Err(e) => {
            println!("âŒ Failed to initialize Whisper service: {}", e);
            eprintln!("âŒ CRITICAL ERROR: {}", e);
            error!("Failed to initialize Whisper service: {}", e);
            std::process::exit(1);
        }
    };
    
    // CORS é…ç½®
    let cors = tower_http::cors::CorsLayer::new()
        .allow_origin(tower_http::cors::Any)
        .allow_methods([axum::http::Method::GET, axum::http::Method::POST])
        .allow_headers(tower_http::cors::Any);
    
    let app = Router::new()
        .route("/upload", post(upload_audio))
        .route("/health", get(health_check))
        .layer(cors)
        .with_state(whisper_service);
    
    // æ”¯æ´ç’°å¢ƒè®Šæ•¸é…ç½®ç«¯å£ï¼Œé»˜èª 8000ï¼Œåœ¨çµ±ä¸€å®¹å™¨ä¸­ä½¿ç”¨ 8080
    let port = std::env::var("BACKEND_PORT").unwrap_or_else(|_| "8000".to_string());
    let bind_addr = format!("0.0.0.0:{}", port);
    let listener = tokio::net::TcpListener::bind(&bind_addr).await.unwrap();
    info!("Server running on http://{}", bind_addr);
    axum::serve(listener, app).await.unwrap();
}

// ä¸Šå‚³è™•ç† - ä½¿ç”¨ whisper-rs
async fn upload_audio(
    State(whisper_service): State<Arc<WhisperService>>,
    mut multipart: Multipart,
) -> Result<Json<TranscriptResponse>, (StatusCode, Json<ErrorResponse>)> {
    info!("Received audio upload request");
    
    // è™•ç† multipart è³‡æ–™
    while let Some(field) = multipart.next_field().await.map_err(|e| {
        error!("Error reading multipart field: {}", e);
        (StatusCode::BAD_REQUEST, Json(ErrorResponse { error: "Invalid multipart data".to_string() }))
    })? {
        
        if field.name() == Some("audio") {
            info!("Processing audio field");
            
            let data = field.bytes().await.map_err(|e| {
                error!("Error reading audio bytes: {}", e);
                (StatusCode::BAD_REQUEST, Json(ErrorResponse { error: "Failed to read audio data".to_string() }))
            })?;
            
            info!("Received audio data: {} bytes", data.len());
            
            // è½‰æ›éŸ³é »æ ¼å¼ (WebM/OGG -> WAV samples)
            let audio_samples = convert_to_wav_samples(&data).map_err(|e| {
                error!("Audio conversion failed: {}", e);
                (StatusCode::UNPROCESSABLE_ENTITY, Json(ErrorResponse { error: "Audio format conversion failed".to_string() }))
            })?;
            
            info!("Audio converted to {} samples", audio_samples.len());
            
            // ä½¿ç”¨ Whisper è½‰éŒ„
            let full_transcript = whisper_service.transcribe(&audio_samples).await.map_err(|e| {
                error!("Transcription failed: {}", e);
                (StatusCode::INTERNAL_SERVER_ERROR, Json(ErrorResponse { error: "Transcription failed".to_string() }))
            })?;
            
            // ç”Ÿæˆç°¡åŒ–æ‘˜è¦
            let summary = generate_simple_summary(&full_transcript);
            
            info!("Transcription completed successfully");
            
            return Ok(Json(TranscriptResponse {
                full_transcript,
                summary,
            }));
        }
    }
    
    warn!("No audio field found in multipart data");
    Err((StatusCode::BAD_REQUEST, Json(ErrorResponse { error: "No audio field found".to_string() })))
}

// éŸ³é »æ ¼å¼è½‰æ› (ç°¡åŒ–ç‰ˆæœ¬ - å‡è¨­è¼¸å…¥æ˜¯ WAV æˆ–å¯ç›´æ¥è§£ç¢¼çš„æ ¼å¼)
fn convert_to_wav_samples(audio_data: &[u8]) -> Result<Vec<f32>, Box<dyn std::error::Error + '_>> {
    info!("Converting audio data to WAV samples");
    
    // é¦–å…ˆå˜—è©¦ä½œç‚º WAV æ–‡ä»¶è®€å–
    if let Ok(samples) = try_read_as_wav(audio_data) {
        info!("Successfully read as WAV format");
        return Ok(samples);
    }
    
    // å¦‚æœä¸æ˜¯ WAVï¼Œå˜—è©¦ä½¿ç”¨ symphonia è§£ç¢¼
    match try_decode_with_symphonia(audio_data) {
        Ok(samples) => {
            info!("Successfully decoded with symphonia");
            Ok(samples)
        },
        Err(e) => {
            error!("Failed to decode audio: {}", e);
            Err(e)
        }
    }
}

fn try_read_as_wav(data: &[u8]) -> Result<Vec<f32>, Box<dyn std::error::Error>> {
    let cursor = std::io::Cursor::new(data);
    let mut reader = hound::WavReader::new(cursor)?;
    
    let samples: Result<Vec<f32>, _> = match reader.spec().sample_format {
        hound::SampleFormat::Float => {
            reader.samples::<f32>().collect()
        },
        hound::SampleFormat::Int => {
            reader.samples::<i16>()
                .map(|s| s.map(|sample| sample as f32 / 32768.0))
                .collect()
        }
    };
    
    let samples = samples?;
    
    // ç¢ºä¿å–®è²é“ï¼Œå¦‚æœæ˜¯ç«‹é«”è²å‰‡å–å¹³å‡
    let channels = reader.spec().channels as usize;
    if channels == 1 {
        Ok(samples)
    } else {
        Ok(samples.chunks(channels)
            .map(|chunk| chunk.iter().sum::<f32>() / channels as f32)
            .collect())
    }
}

fn try_decode_with_symphonia(data: &[u8]) -> Result<Vec<f32>, Box<dyn std::error::Error>> {
    use symphonia::core::formats::FormatOptions;
    use symphonia::core::io::MediaSourceStream;
    use symphonia::core::meta::MetadataOptions;
    use symphonia::core::probe::Hint;
    use symphonia::default::get_probe;
    use symphonia::core::audio::SampleBuffer;
    
    info!("é–‹å§‹ä½¿ç”¨ symphonia è§£ç¢¼éŸ³é »æ•¸æ“šï¼Œå¤§å°: {} bytes", data.len());
    
    // è¤‡è£½æ•¸æ“šåˆ°æ“æœ‰æ‰€æœ‰æ¬Šçš„ Vec ä»¥é¿å…ç”Ÿå‘½é€±æœŸå•é¡Œ
    let owned_data = data.to_vec();
    let cursor = std::io::Cursor::new(owned_data);
    let media_source = MediaSourceStream::new(Box::new(cursor), Default::default());
    
    // å‰µå»ºæ ¼å¼æç¤º - å‘Šè¨´ symphonia é€™å¯èƒ½æ˜¯ WebM æˆ– OGG æ ¼å¼
    let mut hint = Hint::new();
    hint.with_extension("webm");
    hint.with_extension("ogg");
    
    // æ¢æ¸¬æ ¼å¼
    let probe = get_probe();
    let probed = probe
        .format(&hint, media_source, &FormatOptions::default(), &MetadataOptions::default())
        .map_err(|e| {
            error!("æ ¼å¼æ¢æ¸¬å¤±æ•—: {}", e);
            // å€åˆ†ä¸åŒé¡å‹çš„æ ¼å¼éŒ¯èª¤
            match e {
                symphonia::core::errors::Error::IoError(ref io_err) 
                    if io_err.kind() == std::io::ErrorKind::UnexpectedEof => {
                    "éŸ³é »æ–‡ä»¶å¯èƒ½å·²å®Œå…¨è§£æï¼Œä½†ç¼ºå°‘å°¾éƒ¨ä¿¡æ¯ - å˜—è©¦ç¹¼çºŒè™•ç†".to_string()
                },
                _ => format!("ç„¡æ³•è­˜åˆ¥éŸ³é »æ ¼å¼: {}", e)
            }
        })?;
    
    let mut format = probed.format;
    info!("æˆåŠŸè­˜åˆ¥éŸ³é »æ ¼å¼");
    
    // æ‰¾åˆ°ç¬¬ä¸€å€‹éŸ³é »è»Œé“
    let track = format
        .tracks()
        .iter()
        .find(|t| t.codec_params.codec != symphonia::core::codecs::CODEC_TYPE_NULL)
        .ok_or("æ‰¾ä¸åˆ°éŸ³é »è»Œé“")?;
    
    let track_id = track.id;
    info!("æ‰¾åˆ°éŸ³é »è»Œé“ ID: {}, ç·¨è§£ç¢¼å™¨: {:?}", track_id, track.codec_params.codec);
    
    // å‰µå»ºè§£ç¢¼å™¨
    let mut decoder = symphonia::default::get_codecs()
        .make(&track.codec_params, &Default::default())
        .map_err(|e| format!("ç„¡æ³•å‰µå»ºè§£ç¢¼å™¨: {}", e))?;
    
    let mut audio_samples: Vec<f32> = Vec::new();
    let mut sample_buffer: Option<SampleBuffer<f32>> = None;
    
    // è§£ç¢¼éŸ³é »åŒ…
    loop {
        let packet = match format.next_packet() {
            Ok(packet) => packet,
            Err(symphonia::core::errors::Error::ResetRequired) => {
                // é‡ç½®è§£ç¢¼å™¨
                decoder.reset();
                continue;
            },
            Err(symphonia::core::errors::Error::IoError(ref e)) 
                if e.kind() == std::io::ErrorKind::UnexpectedEof => {
                // æ­£å¸¸çš„æ–‡ä»¶çµæŸ - é€™æ˜¯æ­£å¸¸è§£ç¢¼å®Œæˆçš„ä¿¡è™Ÿ
                info!("éŸ³é »è§£ç¢¼æ­£å¸¸å®Œæˆ - åˆ°é”æµæœ«å°¾");
                break;
            },
            Err(e) => {
                // å€åˆ†çœŸæ­£çš„éŒ¯èª¤å’Œæ­£å¸¸çµæŸ
                match e {
                    symphonia::core::errors::Error::IoError(ref io_err) => {
                        if io_err.kind() == std::io::ErrorKind::UnexpectedEof {
                            info!("éŸ³é »è§£ç¢¼æ­£å¸¸å®Œæˆ - IO æµçµæŸ");
                            break;
                        } else {
                            error!("çœŸæ­£çš„ IO éŒ¯èª¤: {}", e);
                            return Err(format!("éŸ³é »è§£ç¢¼ IO éŒ¯èª¤: {}", e).into());
                        }
                    },
                    _ => {
                        warn!("è§£ç¢¼çµæŸæˆ–é‡åˆ°å…¶ä»–éŒ¯èª¤: {}", e);
                        break;
                    }
                }
            }
        };
        
        // åªè™•ç†æˆ‘å€‘æ„Ÿèˆˆè¶£çš„è»Œé“
        if packet.track_id() != track_id {
            continue;
        }
        
        // è§£ç¢¼éŸ³é »åŒ…
        match decoder.decode(&packet) {
            Ok(audio_buf) => {
                // åˆå§‹åŒ–æ¨£æœ¬ç·©è¡å€ï¼ˆåƒ…åœ¨ç¬¬ä¸€æ¬¡æ™‚ï¼‰
                if sample_buffer.is_none() {
                    let spec = *audio_buf.spec();
                    let duration = audio_buf.capacity() as u64;
                    sample_buffer = Some(SampleBuffer::<f32>::new(duration, spec));
                }
                
                if let Some(ref mut buf) = sample_buffer {
                    // ç²å–è²é“æ•¸ï¼ˆåœ¨ copy ä¹‹å‰ï¼‰
                    let channels = audio_buf.spec().channels.count();
                    
                    // å°‡éŸ³é »æ•¸æ“šè¤‡è£½åˆ°æ¨£æœ¬ç·©è¡å€
                    buf.copy_interleaved_ref(audio_buf);
                    
                    // ç²å–æ¨£æœ¬æ•¸æ“š
                    let samples = buf.samples();
                    
                    // è™•ç†å¤šè²é“åˆ°å–®è²é“çš„è½‰æ›
                    if channels == 1 {
                        // å–®è²é“ï¼Œç›´æ¥æ·»åŠ 
                        audio_samples.extend_from_slice(samples);
                    } else {
                        // å¤šè²é“ï¼Œè½‰æ›ç‚ºå–®è²é“ï¼ˆå–å¹³å‡å€¼ï¼‰
                        for chunk in samples.chunks(channels) {
                            let mono_sample: f32 = chunk.iter().sum::<f32>() / channels as f32;
                            audio_samples.push(mono_sample);
                        }
                    }
                }
            },
            Err(e) => {
                warn!("è§£ç¢¼éŸ³é »åŒ…æ™‚å‡ºéŒ¯: {}", e);
                continue;
            }
        }
    }
    
    if audio_samples.is_empty() {
        return Err("æ²’æœ‰è§£ç¢¼å‡ºä»»ä½•éŸ³é »æ•¸æ“š".into());
    }
    
    info!("æˆåŠŸè§£ç¢¼ {} å€‹éŸ³é »æ¨£æœ¬", audio_samples.len());
    
    // ç¢ºä¿æ¨£æœ¬åœ¨åˆç†ç¯„åœå…§ (-1.0 åˆ° 1.0)
    let max_abs = audio_samples.iter().map(|s| s.abs()).fold(0.0f32, f32::max);
    if max_abs > 1.0 {
        info!("éŸ³é »æ¨£æœ¬è¶…å‡ºç¯„åœï¼Œé€²è¡Œæ¨™æº–åŒ–ï¼Œæœ€å¤§å€¼: {}", max_abs);
        for sample in &mut audio_samples {
            *sample /= max_abs;
        }
    }
    
    // Whisper é€šå¸¸æœŸæœ› 16kHz æ¡æ¨£ç‡
    // æ³¨æ„ï¼šé€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æƒ…æ³å¯èƒ½éœ€è¦é‡æ¡æ¨£
    info!("éŸ³é »è§£ç¢¼å®Œæˆï¼Œè¼¸å‡º {} å€‹ PCM æ¨£æœ¬", audio_samples.len());
    
    Ok(audio_samples)
}

// ç°¡å–®æ‘˜è¦ç”Ÿæˆ (å¯æ›¿æ›ç‚ºæ›´æ™ºèƒ½çš„æ–¹æ¡ˆ)
fn generate_simple_summary(transcript: &str) -> String {
    if transcript.trim().is_empty() {
        return "ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼šè½‰éŒ„æ–‡å­—ç‚ºç©º".to_string();
    }
    
    // ç°¡åŒ–ç‰ˆæ‘˜è¦ - å–å‰200å­—
    let summary = if transcript.len() > 200 {
        format!("{}...", &transcript[..200])
    } else {
        transcript.to_string()
    };
    
    // æ·»åŠ é—œæ‡·é‡é»æç¤º
    format!("é—œæ‡·æ‘˜è¦ï¼š{}", summary.trim())
}

async fn health_check() -> Json<serde_json::Value> {
    Json(serde_json::json!({
        "status": "healthy",
        "service": "Care Voice with whisper-rs",
        "version": "1.0.0"
    }))
}
use tracing::{info, error};
use whisper_rs::{WhisperContext, WhisperContextParameters};

fn main() {
    // 初始化日誌並立即刷新
    tracing_subscriber::fmt()
        .with_env_filter("care_voice=debug,whisper_rs=debug")
        .init();

    println!("=== Whisper Model Test ===");
    std::io::Write::flush(&mut std::io::stdout()).unwrap();

    info!("Starting whisper model test...");
    
    // 檢查模型文件是否存在
    let model_path = "./models/ggml-base.bin";
    println!("Checking model path: {}", model_path);
    std::io::Write::flush(&mut std::io::stdout()).unwrap();
    
    match std::fs::metadata(model_path) {
        Ok(metadata) => {
            println!("Model file exists, size: {} bytes", metadata.len());
            std::io::Write::flush(&mut std::io::stdout()).unwrap();
        }
        Err(e) => {
            println!("ERROR: Model file not found: {}", e);
            std::io::Write::flush(&mut std::io::stdout()).unwrap();
            std::process::exit(1);
        }
    }
    
    println!("Attempting to load Whisper model...");
    std::io::Write::flush(&mut std::io::stdout()).unwrap();
    
    match WhisperContext::new_with_params(
        model_path,
        WhisperContextParameters::default(),
    ) {
        Ok(_ctx) => {
            println!("✓ Whisper model loaded successfully!");
            std::io::Write::flush(&mut std::io::stdout()).unwrap();
            info!("Model test completed successfully");
        }
        Err(e) => {
            println!("✗ Failed to load Whisper model: {}", e);
            std::io::Write::flush(&mut std::io::stdout()).unwrap();
            error!("Model loading failed: {}", e);
            std::process::exit(1);
        }
    }
}
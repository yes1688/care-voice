// ===================================
// Whisper å¤šæ¨¡å‹ä¸¦è¡Œè™•ç†æ¶æ§‹
// æ¥­ç•Œé ˜å…ˆçš„æ™ºèƒ½æ¨¡å‹é¸æ“‡èˆ‡ GPU è³‡æºæœ€ä½³åŒ–
// ===================================

use whisper_rs::{WhisperContext, WhisperContextParameters, FullParams, SamplingStrategy};
use std::sync::Arc;
use parking_lot::RwLock;
use tracing::{info, error, warn, debug, span, Level};
use anyhow::{Result, Context as AnyhowContext};
use std::collections::HashMap;
use std::time::Instant;
use crossbeam::channel::{self, Receiver, Sender};
use uuid::Uuid;
use std::sync::atomic::AtomicU64;

// æ•ˆèƒ½ç›£æ§
use metrics::{counter, histogram, gauge};

// CPU è³‡è¨Š
use num_cpus;

/// è½‰éŒ„å“è³ªç­‰ç´š
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum TranscriptionQuality {
    /// è¶…å¿«é€Ÿè™•ç† (0.05x å¯¦æ™‚) - é©ç”¨æ–¼å³æ™‚æ‡‰ç”¨
    Turbo,
    /// å¹³è¡¡è™•ç† (0.1x å¯¦æ™‚) - é©ç”¨æ–¼ä¸€èˆ¬æ‡‰ç”¨
    Balanced,
    /// ä¼æ¥­ç´šå“è³ª (0.15x å¯¦æ™‚) - é©ç”¨æ–¼ä¸­æ–‡å„ªåŒ–
    Medium,
    /// é«˜ç²¾åº¦è™•ç† (0.2x å¯¦æ™‚) - é©ç”¨æ–¼é—œéµæ‡‰ç”¨
    HighAccuracy,
    /// æ¥­ç•Œé ˜å…ˆå“è³ª (0.25x å¯¦æ™‚) - å¤šèªè¨€æœ€ä½³æº–ç¢ºåº¦
    Premium,
}

impl TranscriptionQuality {
    pub fn model_name(&self) -> &'static str {
        match self {
            Self::Turbo => "ggml-tiny.bin",
            Self::Balanced => "ggml-base.bin", 
            Self::Medium => "ggml-medium.bin",
            Self::HighAccuracy => "ggml-large-v2.bin",
            Self::Premium => "ggml-large-v3.bin",
        }
    }

    pub fn target_latency_ms(&self) -> u64 {
        match self {
            Self::Turbo => 50,
            Self::Balanced => 100,
            Self::Medium => 150,
            Self::HighAccuracy => 200,
            Self::Premium => 250,
        }
    }

    /// åˆ¤æ–·æ˜¯å¦é©åˆä¸­æ–‡èªéŸ³è½‰éŒ„
    pub fn is_chinese_optimized(&self) -> bool {
        matches!(self, Self::Medium | Self::Premium)
    }

    /// åˆ¤æ–·æ˜¯å¦é©åˆå°èªè½‰éŒ„
    pub fn is_taiwanese_capable(&self) -> bool {
        matches!(self, Self::Premium)
    }
}

/// è½‰éŒ„ä»»å‹™
#[derive(Debug)]
pub struct TranscriptionTask {
    pub id: Uuid,
    pub audio_samples: Vec<f32>,
    pub quality: TranscriptionQuality,
    pub language: Option<String>,
    pub timestamp: Instant,
}

/// è½‰éŒ„çµæœ
#[derive(Debug, Clone)]
pub struct TranscriptionResult {
    pub task_id: Uuid,
    pub transcript: String,
    pub confidence: Option<f32>,
    pub processing_time_ms: u64,
    pub model_used: String,
    pub segments: Vec<TranscriptSegment>,
}

#[derive(Debug, Clone)]
pub struct TranscriptSegment {
    pub start_time: f32,
    pub end_time: f32,
    pub text: String,
    pub confidence: Option<f32>,
}

/// Whisper æ¨¡å‹å¯¦ä¾‹
struct WhisperModel {
    context: WhisperContext,
    quality: TranscriptionQuality,
    model_path: String,
    creation_time: Instant,
    total_processed: AtomicU64,
    total_processing_time: AtomicU64,
}

impl WhisperModel {
    fn new(model_path: String, quality: TranscriptionQuality) -> Result<Self> {
        let span = span!(Level::INFO, "whisper_model_creation", quality = ?quality);
        let _enter = span.enter();

        info!("æ­£åœ¨åˆå§‹åŒ– {} æ¨¡å‹: {}", quality.model_name(), model_path);
        
        let start_time = Instant::now();
        
        // ğŸš€ æ¥­ç•Œé ˜å…ˆ CUDA å…¼å®¹æ€§æª¢æ¸¬
        let params = WhisperContextParameters::default();
        if let Ok(_) = std::env::var("CUDA_VISIBLE_DEVICES") {
            // GPU å¯è¦‹æ™‚é€²è¡Œæ¶æ§‹å…¼å®¹æ€§æª¢æ¸¬
            if !WhisperModelPool::check_cuda_compatibility() {
                warn!("ğŸš¨ CUDA æ¶æ§‹ä¸å…¼å®¹ï¼Œä½†éµå¾ª GPU ç‚ºç”ŸåŸå‰‡ï¼Œç¹¼çºŒå˜—è©¦ GPU æ¨¡å¼");
                // GPU ç‚ºç”Ÿï¼šå³ä½¿ä¸å…¼å®¹ä¹Ÿä¸é™ç´šåˆ° CPU
            }
        }
        
        let context = WhisperContext::new_with_params(
            &model_path,
            params,
        ).with_context(|| format!("ç„¡æ³•è¼‰å…¥ Whisper æ¨¡å‹: {}", model_path))?;
        
        let creation_time = start_time.elapsed();
        info!("âœ… {} æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œè€—æ™‚: {:?}", quality.model_name(), creation_time);
        
        // è¨˜éŒ„æ¨¡å‹è¼‰å…¥æŒ‡æ¨™
        histogram!("whisper_model_load_time_ms").record(creation_time.as_millis() as f64);
        counter!("whisper_model_loaded_total", "quality" => quality.model_name()).increment(1);

        Ok(Self {
            context,
            quality,
            model_path,
            creation_time: Instant::now(),
            total_processed: AtomicU64::new(0),
            total_processing_time: AtomicU64::new(0),
        })
    }

    async fn transcribe(&self, task: &TranscriptionTask) -> Result<TranscriptionResult> {
        let span = span!(Level::DEBUG, "whisper_transcribe", 
            task_id = %task.id,
            quality = ?self.quality,
            samples = task.audio_samples.len()
        );
        let _enter = span.enter();

        let start_time = Instant::now();
        
        // é…ç½®è½‰éŒ„åƒæ•¸
        let mut params = FullParams::new(SamplingStrategy::Greedy { best_of: 1 });
        
        // æ ¹æ“šå“è³ªç­‰ç´šèª¿æ•´åƒæ•¸
        match self.quality {
            TranscriptionQuality::Turbo => {
                params.set_n_threads(4);
                params.set_print_special(false);
                params.set_print_progress(false);
            },
            TranscriptionQuality::Balanced => {
                params.set_n_threads(6);
                params.set_print_special(false);
                params.set_print_progress(false);
            },
            TranscriptionQuality::Medium => {
                params.set_n_threads(8);
                params.set_temperature(0.1);  // ä¸­æ–‡å„ªåŒ–ï¼šé©åº¦é™ä½æº«åº¦
                params.set_print_special(false);
                params.set_print_progress(false);
            },
            TranscriptionQuality::HighAccuracy => {
                params.set_n_threads(8);
                params.set_temperature(0.0);
                // params.set_best_of(3); // whisper-rs API å·²è®Šæ›´
            },
            TranscriptionQuality::Premium => {
                params.set_n_threads(8);
                params.set_temperature(0.0);  // ä¸­æ–‡æœ€ä½³æº–ç¢ºåº¦è¨­å®š
                params.set_print_special(false);
                params.set_print_progress(false);
                // ä¸­æ–‡å„ªåŒ–ï¼šå¼·åˆ¶è¨­å®šèªè¨€ä»¥æå‡æº–ç¢ºåº¦
                params.set_language(Some("zh"));
            },
        }

        // è¨­å®šèªè¨€
        if let Some(ref language) = task.language {
            params.set_language(Some(language));
        }

        params.set_print_timestamps(true);
        
        // åŸ·è¡Œè½‰éŒ„
        let mut state = self.context.create_state()
            .with_context(|| "ç„¡æ³•å‰µå»º Whisper ç‹€æ…‹")?;
            
        state.full(params, &task.audio_samples)
            .with_context(|| "Whisper è½‰éŒ„å¤±æ•—")?;

        // æ”¶é›†è½‰éŒ„çµæœ
        let num_segments = state.full_n_segments()
            .with_context(|| "ç„¡æ³•ç²å–è½‰éŒ„æ®µæ•¸")?;

        let mut segments = Vec::new();
        let mut full_transcript = String::new();

        for i in 0..num_segments {
            let segment_text = state.full_get_segment_text(i)
                .with_context(|| format!("ç„¡æ³•ç²å–ç¬¬ {} æ®µæ–‡å­—", i))?;
            
            let start_time = state.full_get_segment_t0(i)
                .with_context(|| format!("ç„¡æ³•ç²å–ç¬¬ {} æ®µé–‹å§‹æ™‚é–“", i))? as f32 / 100.0;
                
            let end_time = state.full_get_segment_t1(i)
                .with_context(|| format!("ç„¡æ³•ç²å–ç¬¬ {} æ®µçµæŸæ™‚é–“", i))? as f32 / 100.0;

            segments.push(TranscriptSegment {
                start_time,
                end_time,
                text: segment_text.clone(),
                confidence: None, // Whisper-rs ç›®å‰ä¸æä¾›ä¿¡å¿ƒåˆ†æ•¸
            });

            full_transcript.push_str(&segment_text);
        }

        let processing_time = start_time.elapsed();
        
        // æ›´æ–°çµ±è¨ˆè³‡æ–™
        self.total_processed.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
        self.total_processing_time.fetch_add(
            processing_time.as_millis() as u64, 
            std::sync::atomic::Ordering::Relaxed
        );

        // è¨˜éŒ„æ•ˆèƒ½æŒ‡æ¨™
        histogram!("whisper_transcription_time_ms").record(processing_time.as_millis() as f64);
        counter!("whisper_transcriptions_completed_total", 
            "quality" => self.quality.model_name()).increment(1);
        gauge!("whisper_audio_duration_seconds").set(task.audio_samples.len() as f64 / 16000.0);

        debug!("âœ… è½‰éŒ„å®Œæˆ: {} æ®µ, è€—æ™‚: {:?}", num_segments, processing_time);

        Ok(TranscriptionResult {
            task_id: task.id,
            transcript: full_transcript.trim().to_string(),
            confidence: None,
            processing_time_ms: processing_time.as_millis() as u64,
            model_used: self.quality.model_name().to_string(),
            segments,
        })
    }

    fn get_stats(&self) -> ModelStats {
        let total_processed = self.total_processed.load(std::sync::atomic::Ordering::Relaxed);
        let total_time = self.total_processing_time.load(std::sync::atomic::Ordering::Relaxed);
        
        ModelStats {
            quality: self.quality,
            total_processed,
            total_processing_time_ms: total_time,
            average_processing_time_ms: if total_processed > 0 { 
                total_time / total_processed 
            } else { 
                0 
            },
            uptime: self.creation_time.elapsed(),
        }
    }
}

/// æ¨¡å‹çµ±è¨ˆè³‡æ–™
#[derive(Debug, Clone)]
pub struct ModelStats {
    pub quality: TranscriptionQuality,
    pub total_processed: u64,
    pub total_processing_time_ms: u64,
    pub average_processing_time_ms: u64,
    pub uptime: std::time::Duration,
}

/// Whisper æ¨¡å‹æ±  - æ¥­ç•Œé ˜å…ˆçš„ä¸¦è¡Œè™•ç†æ¶æ§‹
pub struct WhisperModelPool {
    models: RwLock<HashMap<TranscriptionQuality, Arc<WhisperModel>>>,
    task_sender: Sender<TranscriptionTask>,
    result_receiver: Arc<RwLock<HashMap<Uuid, TranscriptionResult>>>,
    worker_handles: Vec<std::thread::JoinHandle<()>>,
}

impl WhisperModelPool {
    /// ğŸš€ æ¥­ç•Œé ˜å…ˆ CUDA æ¶æ§‹å…¼å®¹æ€§æª¢æ¸¬
    fn check_cuda_compatibility() -> bool {
        // æª¢æŸ¥ç’°å¢ƒè®Šæ•¸æ˜¯å¦å¼·åˆ¶ CPU æ¨¡å¼
        if std::env::var("WHISPER_USE_GPU").map(|v| v == "false").unwrap_or(false) {
            info!("ğŸ”§ WHISPER_USE_GPU=falseï¼Œå¼·åˆ¶ä½¿ç”¨ CPU æ¨¡å¼");
            return false;
        }
        
        // å˜—è©¦æª¢æ¸¬ GPU compute capability
        if let Ok(output) = std::process::Command::new("nvidia-smi")
            .arg("--query-gpu=compute_cap")
            .arg("--format=csv,noheader,nounits")
            .output() {
            if let Ok(compute_cap) = std::str::from_utf8(&output.stdout) {
                let compute_cap = compute_cap.trim();
                info!("ğŸ” æª¢æ¸¬åˆ° GPU compute capability: {}", compute_cap);
                
                // RTX 50 ç³»åˆ—æ˜¯ 12.0ï¼Œéœ€è¦å°ˆé–€ç·¨è­¯çš„ç‰ˆæœ¬
                if compute_cap.starts_with("12.") {
                    warn!("âš ï¸ RTX 50 ç³»åˆ— GPU éœ€è¦å°ˆé–€ç·¨è­¯çš„ CUDA ç‰ˆæœ¬");
                    warn!("ğŸ”§ ç•¶å‰äºŒé€²åˆ¶æ–‡ä»¶å¯èƒ½ä¸å…¼å®¹ï¼Œå»ºè­°é‡æ–°ç·¨è­¯æ”¯æ´ compute capability 12.x");
                    // æš«æ™‚ä½¿ç”¨ CPU æ¨¡å¼é¿å…å´©æ½°
                    return false;
                }
                
                // æ”¯æ´çš„æ¶æ§‹ï¼š8.x, 7.x, 6.x, 5.x
                if compute_cap.starts_with("8.") || 
                   compute_cap.starts_with("7.") || 
                   compute_cap.starts_with("6.") || 
                   compute_cap.starts_with("5.") {
                    info!("âœ… GPU æ¶æ§‹å…¼å®¹ï¼Œå•Ÿç”¨ CUDA åŠ é€Ÿ");
                    return true;
                } else {
                    warn!("âš ï¸ ä¸æ”¯æ´çš„ GPU æ¶æ§‹: {}ï¼Œåˆ‡æ›åˆ° CPU æ¨¡å¼", compute_cap);
                    return false;
                }
            }
        }
        
        // å¦‚æœç„¡æ³•æª¢æ¸¬ï¼Œä¿å®ˆåœ°ä½¿ç”¨ CPU æ¨¡å¼
        warn!("â“ ç„¡æ³•æª¢æ¸¬ GPU å…¼å®¹æ€§ï¼Œä½¿ç”¨ CPU æ¨¡å¼ç¢ºä¿ç©©å®š");
        false
    }

    /// å‰µå»ºæ–°çš„æ¨¡å‹æ± 
    pub fn new(model_base_path: &str) -> Result<Self> {
        info!("ğŸš€ æ­£åœ¨åˆå§‹åŒ– Whisper æ¨¡å‹æ± ...");
        
        let mut models = HashMap::new();
        
        // åªè¼‰å…¥æœ€ä½³ä¸­æ–‡æ¨¡å‹ (large-v3)
        for quality in [
            TranscriptionQuality::Premium,
        ] {
            let model_path = format!("{}/{}", model_base_path, quality.model_name());
            
            // æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if !std::path::Path::new(&model_path).exists() {
                warn!("âš ï¸  æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³é: {}", model_path);
                continue;
            }
            
            match WhisperModel::new(model_path, quality) {
                Ok(model) => {
                    models.insert(quality, Arc::new(model));
                    info!("âœ… {} æ¨¡å‹è¼‰å…¥æˆåŠŸ", quality.model_name());
                },
                Err(e) => {
                    error!("âŒ {} æ¨¡å‹è¼‰å…¥å¤±æ•—: {}", quality.model_name(), e);
                }
            }
        }

        if models.is_empty() {
            return Err(anyhow::anyhow!("æ²’æœ‰å¯ç”¨çš„ Whisper æ¨¡å‹"));
        }

        // å‰µå»ºä»»å‹™é€šé“
        let (task_sender, task_receiver) = channel::bounded(1000);
        let result_storage = Arc::new(RwLock::new(HashMap::new()));
        
        // å•Ÿå‹•å·¥ä½œç·šç¨‹
        let worker_handles = Self::start_workers(
            Arc::new(RwLock::new(models.clone())),
            task_receiver,
            result_storage.clone(),
        );

        info!("âœ… Whisper æ¨¡å‹æ± åˆå§‹åŒ–å®Œæˆï¼Œè¼‰å…¥ {} å€‹æ¨¡å‹", models.len());
        counter!("whisper_model_pool_initialized_total").increment(1);
        gauge!("whisper_models_loaded_count").set(models.len() as f64);

        Ok(Self {
            models: RwLock::new(models),
            task_sender,
            result_receiver: result_storage,
            worker_handles,
        })
    }

    /// å•Ÿå‹•èƒŒæ™¯å·¥ä½œç·šç¨‹
    fn start_workers(
        models: Arc<RwLock<HashMap<TranscriptionQuality, Arc<WhisperModel>>>>,
        task_receiver: Receiver<TranscriptionTask>,
        result_storage: Arc<RwLock<HashMap<Uuid, TranscriptionResult>>>,
    ) -> Vec<std::thread::JoinHandle<()>> {
        let num_workers = num_cpus::get().min(8);
        info!("å•Ÿå‹• {} å€‹ Whisper å·¥ä½œç·šç¨‹", num_workers);

        (0..num_workers)
            .map(|worker_id| {
                let models = models.clone();
                let task_receiver = task_receiver.clone();
                let result_storage = result_storage.clone();

                std::thread::spawn(move || {
                    let rt = tokio::runtime::Runtime::new()
                        .expect("ç„¡æ³•å‰µå»º tokio é‹è¡Œæ™‚");

                    while let Ok(task) = task_receiver.recv() {
                        let span = span!(Level::DEBUG, "whisper_worker", 
                            worker_id = worker_id,
                            task_id = %task.id
                        );
                        let _enter = span.enter();

                        // é¸æ“‡åˆé©çš„æ¨¡å‹
                        let model = {
                            let models_guard = models.read();
                            if let Some(model) = models_guard.get(&task.quality) {
                                model.clone()
                            } else {
                                // æ™ºèƒ½å›é€€ï¼šå„ªå…ˆé¸æ“‡ä¸­æ–‡å„ªåŒ–æ¨¡å‹
                                if let Some(model) = models_guard.get(&TranscriptionQuality::Medium) {
                                    warn!("æ‰€è«‹æ±‚çš„å“è³ª {:?} ä¸å¯ç”¨ï¼Œå›é€€åˆ° Medium (ä¸­æ–‡å„ªåŒ–)", task.quality);
                                    model.clone()
                                } else if let Some(model) = models_guard.get(&TranscriptionQuality::Balanced) {
                                    warn!("æ‰€è«‹æ±‚çš„å“è³ª {:?} ä¸å¯ç”¨ï¼Œå›é€€åˆ° Balanced", task.quality);
                                    model.clone()
                                } else if let Some((_, model)) = models_guard.iter().next() {
                                    warn!("æ¨è–¦æ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨æ¨¡å‹");
                                    model.clone()
                                } else {
                                    error!("æ²’æœ‰å¯ç”¨çš„æ¨¡å‹");
                                    continue;
                                }
                            }
                        };

                        // åŸ·è¡Œè½‰éŒ„
                        match rt.block_on(model.transcribe(&task)) {
                            Ok(result) => {
                                debug!("âœ… ä»»å‹™ {} å®Œæˆ", task.id);
                                result_storage.write().insert(task.id, result);
                            },
                            Err(e) => {
                                error!("âŒ ä»»å‹™ {} å¤±æ•—: {}", task.id, e);
                                counter!("whisper_transcription_errors_total").increment(1);
                            }
                        }
                    }

                    info!("å·¥ä½œç·šç¨‹ {} é€€å‡º", worker_id);
                })
            })
            .collect()
    }

    /// æäº¤è½‰éŒ„ä»»å‹™
    pub async fn transcribe_async(
        &self,
        audio_samples: Vec<f32>,
        quality: TranscriptionQuality,
        language: Option<String>,
    ) -> Result<Uuid> {
        let task_id = Uuid::new_v4();
        let task = TranscriptionTask {
            id: task_id,
            audio_samples,
            quality,
            language,
            timestamp: Instant::now(),
        };

        self.task_sender.send(task)
            .with_context(|| "ä»»å‹™ä½‡åˆ—å·²æ»¿ï¼Œç„¡æ³•æäº¤æ–°ä»»å‹™")?;

        counter!("whisper_tasks_submitted_total", 
            "quality" => quality.model_name()).increment(1);

        debug!("ğŸ“ ä»»å‹™ {} å·²æäº¤ (å“è³ª: {:?})", task_id, quality);
        Ok(task_id)
    }

    /// ç²å–è½‰éŒ„çµæœ
    pub fn get_result(&self, task_id: Uuid) -> Option<TranscriptionResult> {
        self.result_receiver.write().remove(&task_id)
    }

    /// é˜»å¡å¼è½‰éŒ„ (å‘å¾Œç›¸å®¹)
    pub async fn transcribe_blocking(
        &self,
        audio_samples: Vec<f32>,
        quality: TranscriptionQuality,
        language: Option<String>,
    ) -> Result<TranscriptionResult> {
        let task_id = self.transcribe_async(audio_samples, quality, language).await?;
        
        // è¼ªè©¢çµæœ
        let start_time = Instant::now();
        let timeout = std::time::Duration::from_secs(90); // å¢åŠ åˆ°90ç§’ä»¥è™•ç†OPUSè§£ç¢¼ä¿®å¾©
        
        loop {
            if let Some(result) = self.get_result(task_id) {
                return Ok(result);
            }
            
            if start_time.elapsed() > timeout {
                return Err(anyhow::anyhow!("è½‰éŒ„è¶…æ™‚"));
            }
            
            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        }
    }

    /// è‡ªé©æ‡‰å“è³ªè½‰éŒ„
    pub async fn transcribe_adaptive(
        &self,
        audio_samples: Vec<f32>,
        target_latency_ms: Option<u64>,
    ) -> Result<TranscriptionResult> {
        // æ ¹æ“šéŸ³é »é•·åº¦å’Œç›®æ¨™å»¶é²é¸æ“‡å“è³ª
        let audio_duration_ms = (audio_samples.len() as f64 / 16.0) as u64;
        
        let quality = if let Some(target) = target_latency_ms {
            if target <= 100 {
                TranscriptionQuality::Turbo
            } else if target <= 200 {
                TranscriptionQuality::Medium
            } else {
                TranscriptionQuality::Premium
            }
        } else if audio_duration_ms <= 5000 {
            TranscriptionQuality::Turbo
        } else if audio_duration_ms <= 30000 {
            TranscriptionQuality::Medium  // å„ªå…ˆä½¿ç”¨ä¸­æ–‡å„ªåŒ–æ¨¡å‹
        } else {
            TranscriptionQuality::Premium  // é•·éŸ³é »ä½¿ç”¨æœ€ä½³æ¨¡å‹
        };

        info!("ğŸ¯ è‡ªé©æ‡‰å“è³ªé¸æ“‡: {:?} (éŸ³é »: {}ms)", quality, audio_duration_ms);
        self.transcribe_blocking(audio_samples, quality, None).await
    }

    /// ä¸­æ–‡å„ªåŒ–è½‰éŒ„ - é‡å°æ­£é«”ä¸­æ–‡å’Œå°èª
    pub async fn transcribe_chinese_optimized(
        &self,
        audio_samples: Vec<f32>,
        is_taiwanese: bool,
        language_hint: Option<String>,
    ) -> Result<TranscriptionResult> {
        let audio_duration_ms = (audio_samples.len() as f64 / 16.0) as u64;
        
        // å°èªå¼·åˆ¶ä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼Œä¸­æ–‡æ ¹æ“šé•·åº¦é¸æ“‡
        let quality = if is_taiwanese {
            TranscriptionQuality::Premium
        } else if audio_duration_ms <= 10000 {
            TranscriptionQuality::Medium
        } else {
            TranscriptionQuality::Premium
        };
        
        let language = language_hint.unwrap_or_else(|| {
            if is_taiwanese {
                "zh".to_string()  // å°èªä»ä½¿ç”¨ä¸­æ–‡èªè¨€ä»£ç¢¼
            } else {
                "zh".to_string()  // æ­£é«”ä¸­æ–‡
            }
        });

        info!("ğŸ€„ ä¸­æ–‡å„ªåŒ–è½‰éŒ„: {:?}, å°èª: {}, èªè¨€: {}", quality, is_taiwanese, language);
        self.transcribe_blocking(audio_samples, quality, Some(language)).await
    }

    /// ç²å–æ¨¡å‹æ± çµ±è¨ˆè³‡æ–™
    pub fn get_stats(&self) -> Vec<ModelStats> {
        self.models.read()
            .values()
            .map(|model| model.get_stats())
            .collect()
    }

    /// æª¢æŸ¥å¥åº·ç‹€æ…‹
    pub fn health_check(&self) -> bool {
        !self.models.read().is_empty()
    }
}

impl Drop for WhisperModelPool {
    fn drop(&mut self) {
        info!("æ­£åœ¨é—œé–‰ Whisper æ¨¡å‹æ± ...");
        // å·¥ä½œç·šç¨‹æœƒåœ¨é€šé“é—œé–‰æ™‚è‡ªå‹•é€€å‡º
    }
}
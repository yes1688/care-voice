# 使用 NVIDIA 官方 CUDA 基礎映像
FROM docker.io/nvidia/cuda:12.1.1-devel-ubuntu20.04

# 設置非互動模式
ENV DEBIAN_FRONTEND=noninteractive
ENV TZ=Asia/Taipei

# 安裝系統依賴
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    nginx \
    supervisor \
    curl \
    ca-certificates \
    ffmpeg \
    git \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 創建 python3 符號鏈接
RUN ln -sf /usr/bin/python3 /usr/bin/python

# 創建應用用戶和目錄
RUN groupadd -g 1000 app && \
    useradd -u 1000 -g app -m -s /bin/bash app && \
    mkdir -p /app/models /var/log/supervisor /run/nginx

# 升級 pip 並安裝最新的 PyTorch with CUDA 12.8
RUN python3 -m pip install --upgrade pip

# 嘗試安裝支持 CUDA 12.8 的最新 PyTorch
RUN python3 -m pip install --no-cache-dir \
    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128 || \
    python3 -m pip install --no-cache-dir \
    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# 安裝 OpenAI Whisper 和其他依賴
RUN python3 -m pip install --no-cache-dir \
    openai-whisper \
    numpy \
    soundfile \
    librosa \
    pydub \
    python-multipart

# 複製前端文件
COPY frontend/dist /usr/share/nginx/html
RUN chown -R www-data:www-data /usr/share/nginx/html

# 創建增強的 GPU Whisper 服務器
COPY gpu_whisper_server_cuda_native.py /app/gpu_whisper_server.py
RUN chmod +x /app/gpu_whisper_server.py

# 複製配置文件
COPY unified-nginx.conf /etc/nginx/nginx.conf
COPY supervisord_cuda_native.conf /etc/supervisor/supervisord.conf

# 設置權限
RUN mkdir -p /var/log/nginx /var/log/supervisor && \
    chown -R www-data:www-data /var/log/nginx && \
    chown -R app:app /app

# 設置 CUDA 環境變量
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

WORKDIR /app
EXPOSE 8000

# 健康檢查
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 啟動 supervisord
CMD ["/usr/bin/supervisord", "-c", "/etc/supervisor/supervisord.conf"]
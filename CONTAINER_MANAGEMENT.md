# Care Voice å®¹å™¨ç‰ˆæœ¬ç®¡ç†æŒ‡å—

## ğŸ¯ å¤šå®¹å™¨ç’°å¢ƒæ¦‚è¦½

Care Voice é …ç›®ç›®å‰é‹è¡Œå¤šå€‹å®¹å™¨ï¼Œæä¾›ä¸åŒçš„åŠŸèƒ½å’Œå…¼å®¹æ€§æ”¯æ´ã€‚

### ç•¶å‰å®¹å™¨ç‹€æ…‹ âœ…

| å®¹å™¨åç¨± | ç«¯å£ | ç‹€æ…‹ | ä¸»è¦åŠŸèƒ½ | GPU æ”¯æ´ |
|----------|------|------|----------|----------|
| **care-voice-rtx50** | **8001** | **ğŸŸ¢ é‹è¡Œä¸­** | **RTX 50 ç³»åˆ— GPU åŠ é€Ÿ Whisper** | **RTX 5070 Ti (CDI)** |
| care-voice-gpu | 8000 | ğŸŸ¡ èˆŠç‰ˆæœ¬ | èˆŠç‰ˆ GPU åŠ é€Ÿ | å‚³çµ± GPU å­˜å– |
| care-voice-cpu | 3001 | ğŸŸ¡ èˆŠç‰ˆæœ¬ | CPU å›é€€ç‰ˆæœ¬ | ä¸æ”¯æ´ |
| care-voice-unified | 3002 | ğŸ”´ åœç”¨ | å¯¦é©—æ€§çµ±ä¸€æœå‹™ | ä¸æ”¯æ´ |

## ğŸš€ æ¨è–¦ä½¿ç”¨

### RTX 50 ç³»åˆ—ä¸»è¦å®¹å™¨ (æ¨è–¦) â­â­â­â­â­

```bash
# å•Ÿå‹• RTX 50 ç³»åˆ— GPU åŠ é€Ÿå®¹å™¨ (æ¨è–¦)
podman run -d --name care-voice-rtx50 \
    --device nvidia.com/gpu=all \
    -p 8001:8001 \
    -e NVIDIA_VISIBLE_DEVICES=all \
    care-voice-rtx50:latest

# è¨ªå•æœå‹™
curl http://localhost:8001/health
firefox http://localhost:8001
```

**å„ªå‹¢**:
- âœ… RTX 5070 Ti GPU åŠ é€Ÿ (31,250 GFLOPS)
- âœ… æ··åˆç²¾åº¦ FP16 æ¨ç†å„ªåŒ–
- âœ… å¤šä¸–ä»£ GPU å…¼å®¹ (RTX 50/40/30/20 + GTX 10)
- âœ… CDI GPU å­˜å–æŠ€è¡“
- âœ… æœ€æ–° CUDA 12.8 + PyTorch nightly cu128

## ğŸ“‹ å®¹å™¨ç®¡ç†æ“ä½œ

### æª¢æŸ¥æ‰€æœ‰å®¹å™¨ç‹€æ…‹

```bash
# æŸ¥çœ‹æ‰€æœ‰ Care Voice å®¹å™¨
podman ps -a | grep care-voice

# æª¢æŸ¥ RTX 50 ç³»åˆ—å®¹å™¨è©³ç´°ç‹€æ…‹
podman inspect care-voice-rtx50 | grep -E "State|Status|ExitCode"

# æŸ¥çœ‹å®¹å™¨è³‡æºä½¿ç”¨
podman stats care-voice-rtx50
```

### å®¹å™¨æ—¥èªŒç®¡ç†

```bash
# RTX 50 ç³»åˆ—å®¹å™¨æ—¥èªŒ
podman logs care-voice-rtx50

# GPU è¨ºæ–·æ—¥èªŒ
podman exec care-voice-rtx50 cat /app/logs/gpu_diagnostics_report.json

# Whisper æœå‹™æ—¥èªŒ
podman exec care-voice-rtx50 cat /app/logs/rtx50_whisper_service.log

# ç³»çµ±æœå‹™ç‹€æ…‹
podman exec care-voice-rtx50 supervisorctl status
```

### å®¹å™¨å¥åº·æª¢æŸ¥

```bash
# RTX 50 ç³»åˆ—å¥åº·æª¢æŸ¥
curl http://localhost:8001/health

# GPU ç‹€æ…‹æª¢æŸ¥
podman exec care-voice-rtx50 nvidia-smi

# å®Œæ•´ GPU è¨ºæ–·
podman exec care-voice-rtx50 python3 /app/gpu_diagnostics.py
```

## ğŸ”„ ç‰ˆæœ¬å‡ç´šç­–ç•¥

### å¾èˆŠç‰ˆæœ¬å‡ç´šåˆ° RTX 50 ç³»åˆ—

```bash
# 1. å‚™ä»½èˆŠå®¹å™¨æ•¸æ“š (å¯é¸)
podman cp care-voice-gpu:/app/logs ./backup-logs-$(date +%Y%m%d) 2>/dev/null || true

# 2. å„ªé›…åœæ­¢èˆŠå®¹å™¨
podman stop care-voice-gpu care-voice-cpu care-voice-unified 2>/dev/null || true

# 3. éƒ¨ç½² RTX 50 ç³»åˆ—æ–°å®¹å™¨
podman run -d --name care-voice-rtx50 \
    --device nvidia.com/gpu=all \
    -p 8001:8001 \
    care-voice-rtx50:latest

# 4. é©—è­‰å‡ç´šæˆåŠŸ
curl http://localhost:8001/health
podman exec care-voice-rtx50 python3 /app/gpu_diagnostics.py

# 5. æ¸…ç†èˆŠå®¹å™¨ (ç¢ºèªæ–°å®¹å™¨æ­£å¸¸å¾ŒåŸ·è¡Œ)
podman rm care-voice-gpu care-voice-cpu care-voice-unified 2>/dev/null || true
```

### å®¹å™¨ç‰ˆæœ¬å›é€€ (ç·Šæ€¥æƒ…æ³)

```bash
# å¦‚æœ RTX 50 ç³»åˆ—å‡ºç¾å•é¡Œï¼Œå¿«é€Ÿå›é€€åˆ° GPU ç‰ˆæœ¬
podman stop care-voice-rtx50
podman run -d --name care-voice-gpu-fallback \
    --gpus all -p 8000:8000 \
    care-voice-legacy:latest

# è¨ªå•å›é€€æœå‹™
curl http://localhost:8000/health
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### RTX 50 ç³»åˆ—å®¹å™¨å•é¡Œ

```bash
# æª¢æŸ¥å®¹å™¨æ˜¯å¦æ­£å¸¸å•Ÿå‹•
podman ps | grep care-voice-rtx50

# æª¢æŸ¥ GPU å¯è¦‹æ€§
podman exec care-voice-rtx50 nvidia-smi

# æª¢æŸ¥ CDI GPU è¨­å‚™
nvidia-ctk cdi list | grep nvidia.com/gpu

# é‡å•Ÿå®¹å™¨æœå‹™
podman restart care-voice-rtx50
```

### ç«¯å£è¡çªè§£æ±º

```bash
# æª¢æŸ¥ç«¯å£ä½”ç”¨
netstat -tlnp | grep -E "800[01]|300[12]"

# åœæ­¢è¡çªçš„å®¹å™¨
podman stop $(podman ps -q --filter "publish=8001")

# ä½¿ç”¨ä¸åŒç«¯å£å•Ÿå‹•
podman run -d --name care-voice-rtx50-alt \
    --device nvidia.com/gpu=all \
    -p 8002:8001 \
    care-voice-rtx50:latest
```

### è³‡æºæ¸…ç†

```bash
# æ¸…ç†æ‰€æœ‰åœæ­¢çš„ Care Voice å®¹å™¨
podman container prune --filter "label=project=care-voice"

# æ¸…ç†æœªä½¿ç”¨çš„æ˜ åƒ
podman image prune -f

# æŸ¥çœ‹ç£ç¢Ÿä½¿ç”¨æƒ…æ³
podman system df
```

## ğŸ“Š å®¹å™¨æ€§èƒ½ç›£æ§

### å¯¦æ™‚ç›£æ§

```bash
# RTX 50 ç³»åˆ—å®¹å™¨è³‡æºä½¿ç”¨
watch -n 1 podman stats care-voice-rtx50

# GPU ä½¿ç”¨ç‡ç›£æ§
podman exec care-voice-rtx50 watch -n 1 nvidia-smi

# ç³»çµ±æ•´é«”ç‹€æ³
htop
```

### æ€§èƒ½æŒ‡æ¨™æ”¶é›†

```bash
# å®¹å™¨ CPU/è¨˜æ†¶é«”ä½¿ç”¨
podman exec care-voice-rtx50 ps aux | head -10

# GPU è¨˜æ†¶é«”ä½¿ç”¨
podman exec care-voice-rtx50 python3 -c "import torch; print(f'VRAM: {torch.cuda.memory_allocated()/1024**3:.2f}GB')"

# ç£ç¢Ÿ I/O ç‹€æ³
podman exec care-voice-rtx50 iostat -x 1 3
```

## ğŸ“ å®¹å™¨æ–‡ä»¶ç®¡ç†

### é‡è¦é…ç½®æ–‡ä»¶ä½ç½®

```bash
# RTX 50 ç³»åˆ—å®¹å™¨å…§éƒ¨çµæ§‹
podman exec care-voice-rtx50 find /app -type f -name "*.py" | head -10
podman exec care-voice-rtx50 ls -la /app/logs/

# é…ç½®æ–‡ä»¶å‚™ä»½
podman cp care-voice-rtx50:/etc/supervisor/supervisord.conf ./supervisor-backup.conf
podman cp care-voice-rtx50:/etc/nginx/nginx.conf ./nginx-backup.conf
```

### å‹•æ…‹é…ç½®æ›´æ–°

```bash
# æ›´æ–° Supervisor é…ç½®
podman cp new-supervisord.conf care-voice-rtx50:/etc/supervisor/supervisord.conf
podman exec care-voice-rtx50 supervisorctl reread
podman exec care-voice-rtx50 supervisorctl reload

# é‡è¼‰ Nginx é…ç½®
podman cp new-nginx.conf care-voice-rtx50:/etc/nginx/nginx.conf
podman exec care-voice-rtx50 nginx -s reload
```

## ğŸ”’ å®‰å…¨å’Œç¶­è­·

### å®šæœŸç¶­è­·ä»»å‹™

```bash
# æ¯é€±å®¹å™¨å¥åº·æª¢æŸ¥
curl -f http://localhost:8001/health || echo "å¥åº·æª¢æŸ¥å¤±æ•—"

# æ¯æœˆæ—¥èªŒè¼ªè½‰
podman exec care-voice-rtx50 logrotate /etc/logrotate.conf

# å­£åº¦æ€§èƒ½åŸºæº–æ¸¬è©¦
podman exec care-voice-rtx50 python3 /app/gpu_diagnostics.py
```

### å‚™ä»½ç­–ç•¥

```bash
# å®Œæ•´å®¹å™¨æ˜ åƒå‚™ä»½
podman commit care-voice-rtx50 care-voice-rtx50-backup:$(date +%Y%m%d)

# é…ç½®å’Œæ—¥èªŒå‚™ä»½
podman cp care-voice-rtx50:/app/logs ./backup-logs-$(date +%Y%m%d)
podman cp care-voice-rtx50:/etc/supervisor ./backup-config-$(date +%Y%m%d)
```

---

**ç‹€æ…‹**: ğŸŸ¢ RTX 50 ç³»åˆ—å®¹å™¨ç®¡ç†ç³»çµ±å°±ç·’  
**æœ€å¾Œæ›´æ–°**: 2025-07-24  
**ä¸»è¦å®¹å™¨**: care-voice-rtx50 (ç«¯å£ 8001, RTX 5070 Ti GPU åŠ é€Ÿ)  
**ç®¡ç†é‡é»**: CDI GPU å­˜å– + å¤šä¸–ä»£å…¼å®¹ + æ··åˆç²¾åº¦å„ªåŒ–
#!/usr/bin/env python3
"""
æ¸¬è©¦ PyTorch nightly ç‰ˆæœ¬å° RTX 5070 Ti (sm_120) çš„æ”¯æŒ
"""

import subprocess
import sys

def install_pytorch_nightly():
    """å®‰è£ PyTorch nightly ç‰ˆæœ¬"""
    print("ğŸ”„ å®‰è£ PyTorch nightly ç‰ˆæœ¬...")
    
    # å…ˆå¸è¼‰ç¾æœ‰ç‰ˆæœ¬
    subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "torch", "torchvision", "torchaudio"])
    
    # å®‰è£ nightly ç‰ˆæœ¬
    cmd = [
        sys.executable, "-m", "pip", "install", "--pre", 
        "torch", "torchvision", "torchaudio", 
        "--index-url", "https://download.pytorch.org/whl/nightly/cu124"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    print(f"å®‰è£çµæœ: {result.returncode}")
    if result.returncode != 0:
        print(f"éŒ¯èª¤: {result.stderr}")
        return False
    
    return True

def test_gpu_support():
    """æ¸¬è©¦ GPU æ”¯æŒ"""
    print("ğŸ§ª æ¸¬è©¦ GPU æ”¯æŒ...")
    
    try:
        import torch
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"GPU åç¨±: {torch.cuda.get_device_name(0)}")
            props = torch.cuda.get_device_properties(0)
            print(f"è¨ˆç®—èƒ½åŠ›: {props.major}.{props.minor}")
            
            # æ¸¬è©¦åŸºæœ¬é‹ç®—
            try:
                x = torch.tensor([1.0, 2.0, 3.0]).cuda()
                y = x * 2
                print(f"âœ… GPU é‹ç®—æˆåŠŸ: {y.cpu().numpy()}")
                return True
            except Exception as e:
                print(f"âŒ GPU é‹ç®—å¤±æ•—: {e}")
                return False
        else:
            print("âŒ CUDA ä¸å¯ç”¨")
            return False
            
    except ImportError as e:
        print(f"âŒ ç„¡æ³•å°å…¥ PyTorch: {e}")
        return False

def test_whisper_gpu():
    """æ¸¬è©¦ Whisper GPU æ”¯æŒ"""
    print("ğŸ¤ æ¸¬è©¦ Whisper GPU æ”¯æŒ...")
    
    try:
        import whisper
        import torch
        import numpy as np
        
        # å˜—è©¦è¼‰å…¥ GPU æ¨¡å‹
        model = whisper.load_model("tiny", device="cuda")
        print("âœ… Whisper GPU æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        
        # æ¸¬è©¦è½‰éŒ„
        audio = np.random.randn(16000).astype(np.float32)  # 1ç§’éš¨æ©ŸéŸ³é »
        result = model.transcribe(audio, fp16=True)
        print(f"âœ… GPU è½‰éŒ„æ¸¬è©¦æˆåŠŸ: {result['text'][:50]}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Whisper GPU æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ PyTorch nightly æ¸¬è©¦é–‹å§‹")
    print("=" * 50)
    
    # å®‰è£ nightly ç‰ˆæœ¬
    if install_pytorch_nightly():
        print("âœ… PyTorch nightly å®‰è£æˆåŠŸ")
        
        # æ¸¬è©¦ GPU æ”¯æŒ
        if test_gpu_support():
            print("âœ… GPU æ”¯æŒæ¸¬è©¦æˆåŠŸ")
            
            # æ¸¬è©¦ Whisper
            if test_whisper_gpu():
                print("âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼RTX 5070 Ti GPU åŠ é€Ÿå¯ç”¨")
            else:
                print("âš ï¸ Whisper GPU æ¸¬è©¦å¤±æ•—ï¼Œä½†åŸºç¤ GPU é‹ç®—å¯ç”¨")
        else:
            print("âŒ GPU æ”¯æŒæ¸¬è©¦å¤±æ•—")
    else:
        print("âŒ PyTorch nightly å®‰è£å¤±æ•—")